{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1399887,"sourceType":"datasetVersion","datasetId":817870}],"dockerImageVersionId":30558,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-21T06:19:34.093711Z","iopub.execute_input":"2023-10-21T06:19:34.09412Z","iopub.status.idle":"2023-10-21T06:19:34.545095Z","shell.execute_reply.started":"2023-10-21T06:19:34.094068Z","shell.execute_reply":"2023-10-21T06:19:34.544207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load your dataset\ndataset_path='/kaggle/input/fraud-detection/fraudTrain.csv'\nfraud_data = pd.read_csv(dataset_path)\n\n# Display basic information about the dataset\nprint(fraud_data.info())\n\n# Summary statistics for numerical columns\nprint(fraud_data.describe())\n\n# Check for missing values\nprint(fraud_data.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:20:31.264603Z","iopub.execute_input":"2023-10-21T06:20:31.26523Z","iopub.status.idle":"2023-10-21T06:20:47.939627Z","shell.execute_reply.started":"2023-10-21T06:20:31.265196Z","shell.execute_reply":"2023-10-21T06:20:47.938394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\n\n# Explore categorical variables\ncategorical_columns = ['merchant', 'category', 'gender','city']\n\nfor column in categorical_columns:\n    plt.figure(figsize=(8, 4))\n    sns.countplot(data=fraud_data, x=column, palette='Set3')\n    plt.title(f'Distribution of {column}')\n    plt.xticks(rotation=45)\n    plt.show()\n\n# Convert 'trans_date_trans_time' and 'dob' to datetime\nfraud_data['trans_date_trans_time'] = pd.to_datetime(fraud_data['trans_date_trans_time'])\nfraud_data['dob'] = pd.to_datetime(fraud_data['dob'])\n\n# Time-based analysis\nplt.figure(figsize=(12, 5))\nfraud_data['trans_date_trans_time'].dt.hour.plot(kind='hist', bins=24, rwidth=0.9, color='skyblue')\nplt.title('Hourly Transaction Distribution')\nplt.xlabel('Hour of the Day')\nplt.ylabel('Frequency')\nplt.show()\n\n# Visualize the class distribution\nplt.figure(figsize=(6, 4))\nfraud_data['is_fraud'].value_counts().plot(kind='bar', color=['skyblue', 'salmon'])\nplt.title('Class Distribution (0: Non-Fraud, 1: Fraud)')\nplt.xlabel('Class')\nplt.ylabel('Count')\nplt.xticks(rotation=0)\nplt.show()\n\n# Geospatial data - Scatter plot of transactions\nplt.figure(figsize=(10, 8))\nplt.scatter(fraud_data['merch_long'], fraud_data['merch_lat'], c=fraud_data['is_fraud'], cmap='coolwarm', alpha=0.5)\nplt.title('Geospatial Distribution of Transactions (Fraud vs. Non-Fraud)')\nplt.xlabel('Merchant Longitude')\nplt.ylabel('Merchant Latitude')\nplt.colorbar(label='0: Non-Fraud, 1: Fraud')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:24:48.783414Z","iopub.execute_input":"2023-10-21T06:24:48.783831Z","iopub.status.idle":"2023-10-21T06:25:42.200656Z","shell.execute_reply.started":"2023-10-21T06:24:48.7838Z","shell.execute_reply":"2023-10-21T06:25:42.198943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature 1: Transaction Amount Decimal Part\nfraud_data['amt_decimal'] = fraud_data['amt'] % 1\n\n# Ensure 'trans_date_trans_time' is treated as a string\nfraud_data['trans_date_trans_time'] = fraud_data['trans_date_trans_time'].astype(str)\n\n# Feature 2: Age of Cardholder at the Time of Transaction\nfraud_data['transaction_date'] = pd.to_datetime(fraud_data['trans_date_trans_time'].str.split(' ').str[0])\nfraud_data['cardholder_age'] = (fraud_data['transaction_date'] - pd.to_datetime(fraud_data['dob'])).dt.days // 365\n\n# Feature 3: Transaction Amount to City Population Ratio\nfraud_data['amt_to_city_pop_ratio'] = fraud_data['amt'] / fraud_data['city_pop']\n\n# Display the updated dataset with new features\nprint(fraud_data[['amt_decimal', 'cardholder_age', 'amt_to_city_pop_ratio']].head())","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:28:22.598191Z","iopub.execute_input":"2023-10-21T06:28:22.598697Z","iopub.status.idle":"2023-10-21T06:28:30.657224Z","shell.execute_reply.started":"2023-10-21T06:28:22.598659Z","shell.execute_reply":"2023-10-21T06:28:30.655969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a list of columns to drop\ncolumns_to_drop = [\n    'Unnamed: 0',        # An index or identifier\n    'cc_num',            # Masked credit card numbers\n    'trans_date_trans_time',  #We have unix_time\n    'transaction_date',  # Same as unix_time\n    'first',             # First name\n    'last',              # Last name\n    'street',            # Street address\n    'city',              # City (state information is more relevant)\n    'state',             # State (zip code and lat/long provide location info)\n    'zip',               # Zip code (redundant with lat/long)\n    'dob',               # Date of birth (we've calculated cardholder_age)\n    'trans_num',         # Transaction number or identifier\n]\n\n# Drop the specified columns\nfraud_data = fraud_data.drop(columns=columns_to_drop)\n\n# Display the updated dataset\nprint(fraud_data.head())\n","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:28:46.458699Z","iopub.execute_input":"2023-10-21T06:28:46.459127Z","iopub.status.idle":"2023-10-21T06:28:46.56561Z","shell.execute_reply.started":"2023-10-21T06:28:46.459079Z","shell.execute_reply":"2023-10-21T06:28:46.56441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load your testing dataset\ntestdataset_path='/kaggle/input/fraud-detection/fraudTest.csv'\ntesting_data = pd.read_csv(testdataset_path)\n\n# Handle missing values (if any)\ntesting_data = testing_data.dropna()","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:30:04.598524Z","iopub.execute_input":"2023-10-21T06:30:04.598951Z","iopub.status.idle":"2023-10-21T06:30:11.34142Z","shell.execute_reply.started":"2023-10-21T06:30:04.59892Z","shell.execute_reply":"2023-10-21T06:30:11.340505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature 1: Transaction Amount Decimal Part\ntesting_data['amt_decimal'] = testing_data['amt'] % 1\n\n# Ensure 'trans_date_trans_time' is treated as a string\ntesting_data['trans_date_trans_time'] = testing_data['trans_date_trans_time'].astype(str)\n\n# Feature 2: Age of Cardholder at the Time of Transaction\ntesting_data['transaction_date'] = pd.to_datetime(testing_data['trans_date_trans_time'].str.split(' ').str[0])\ntesting_data['cardholder_age'] = (testing_data['transaction_date'] - pd.to_datetime(testing_data['dob'])).dt.days // 365\n\n# Feature 3: Transaction Amount to City Population Ratio\ntesting_data['amt_to_city_pop_ratio'] = testing_data['amt'] / testing_data['city_pop']\n\n# Display the updated dataset with new features\nprint(testing_data[['amt_decimal', 'cardholder_age', 'amt_to_city_pop_ratio']].head())","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:30:19.128309Z","iopub.execute_input":"2023-10-21T06:30:19.128869Z","iopub.status.idle":"2023-10-21T06:30:21.09847Z","shell.execute_reply.started":"2023-10-21T06:30:19.12883Z","shell.execute_reply":"2023-10-21T06:30:21.096995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop the specified columns\ntesting_data = testing_data.drop(columns=columns_to_drop)","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:30:38.36043Z","iopub.execute_input":"2023-10-21T06:30:38.360829Z","iopub.status.idle":"2023-10-21T06:30:38.449424Z","shell.execute_reply.started":"2023-10-21T06:30:38.360797Z","shell.execute_reply":"2023-10-21T06:30:38.448031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Handle missing values (if any)\nfraud_data = fraud_data.dropna()\n\n# Encode categorical variables using LabelEncoder\nfrom sklearn.preprocessing import LabelEncoder\nlabel_encoder = LabelEncoder()\n\ncategorical_columns = ['gender', 'merchant', 'category', 'job']\nfor col in categorical_columns:\n    fraud_data[col] = label_encoder.fit_transform(fraud_data[col])\n    testing_data[col] = label_encoder.fit_transform(testing_data[col])","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:30:52.718421Z","iopub.execute_input":"2023-10-21T06:30:52.718817Z","iopub.status.idle":"2023-10-21T06:30:56.184901Z","shell.execute_reply.started":"2023-10-21T06:30:52.718788Z","shell.execute_reply":"2023-10-21T06:30:56.183616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n# Split the data into features (X) and the target variable (y)\nX_train = fraud_data.drop(columns=['is_fraud'])\ny_train = fraud_data['is_fraud']","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:31:07.500051Z","iopub.execute_input":"2023-10-21T06:31:07.50051Z","iopub.status.idle":"2023-10-21T06:31:07.545752Z","shell.execute_reply.started":"2023-10-21T06:31:07.500479Z","shell.execute_reply":"2023-10-21T06:31:07.544407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the testing data into features (X_test) and the target variable (y_test)\nX_val = testing_data.drop(columns=['is_fraud'])\ny_val = testing_data['is_fraud']","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:31:26.364416Z","iopub.execute_input":"2023-10-21T06:31:26.364819Z","iopub.status.idle":"2023-10-21T06:31:26.403087Z","shell.execute_reply.started":"2023-10-21T06:31:26.364789Z","shell.execute_reply":"2023-10-21T06:31:26.401806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\n# Create a logistic regression model\nmodel = LogisticRegression()\n\n# Train the model on the training data\nmodel.fit(X_train, y_train)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:32:17.702237Z","iopub.execute_input":"2023-10-21T06:32:17.702693Z","iopub.status.idle":"2023-10-21T06:32:21.790603Z","shell.execute_reply.started":"2023-10-21T06:32:17.702657Z","shell.execute_reply":"2023-10-21T06:32:21.788958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n     \n\n# Make predictions on the validation data\ny_pred = model.predict(X_val)\n\n# Evaluate the model's performance on the validation data\naccuracy = accuracy_score(y_val, y_pred)\nprecision = precision_score(y_val, y_pred)\nrecall = recall_score(y_val, y_pred)\nf1 = f1_score(y_val, y_pred)\nroc_auc = roc_auc_score(y_val, y_pred)\n\n# Print or store the evaluation results\nprint(f\"Accuracy: {accuracy}\")\nprint(f\"Precision: {precision}\")\nprint(f\"Recall: {recall}\")\nprint(f\"F1 Score: {f1}\")\nprint(f\"ROC AUC Score: {roc_auc}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:32:58.101509Z","iopub.execute_input":"2023-10-21T06:32:58.101967Z","iopub.status.idle":"2023-10-21T06:32:58.901551Z","shell.execute_reply.started":"2023-10-21T06:32:58.10193Z","shell.execute_reply":"2023-10-21T06:32:58.90023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}